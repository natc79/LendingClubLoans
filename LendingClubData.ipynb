{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Data on Loans\n",
    "\n",
    "This code seeks to optimize the memory needed to store financial lending data from 2007-2011on approved loans from Lending Club (https://www.lendingclub.com/info/download-data.action).  The objective of the code is to handle the data in chunks so that maximum memory needed at any give time is 10MB in size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  1077501  1296599.0     5000.0       5000.0           4975.0   36 months   \n",
      "1  1077430  1314167.0     2500.0       2500.0           2500.0   60 months   \n",
      "2  1077175  1313524.0     2400.0       2400.0           2400.0   36 months   \n",
      "3  1076863  1277178.0    10000.0      10000.0          10000.0   36 months   \n",
      "4  1075358  1311748.0     3000.0       3000.0           3000.0   60 months   \n",
      "\n",
      "  int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
      "0   10.65%       162.87     B        B2                       NaN  10+ years   \n",
      "1   15.27%        59.83     C        C4                     Ryder   < 1 year   \n",
      "2   15.96%        84.33     C        C5                       NaN  10+ years   \n",
      "3   13.49%       339.31     C        C1       AIR RESOURCES BOARD  10+ years   \n",
      "4   12.69%        67.79     B        B5  University Medical Group     1 year   \n",
      "\n",
      "  home_ownership  annual_inc verification_status    issue_d  loan_status  \\\n",
      "0           RENT     24000.0            Verified 2011-12-01   Fully Paid   \n",
      "1           RENT     30000.0     Source Verified 2011-12-01  Charged Off   \n",
      "2           RENT     12252.0        Not Verified 2011-12-01   Fully Paid   \n",
      "3           RENT     49200.0     Source Verified 2011-12-01   Fully Paid   \n",
      "4           RENT     80000.0     Source Verified 2011-12-01      Current   \n",
      "\n",
      "  pymnt_plan         purpose                 title zip_code addr_state    dti  \\\n",
      "0          n     credit_card              Computer    860xx         AZ  27.65   \n",
      "1          n             car                  bike    309xx         GA   1.00   \n",
      "2          n  small_business  real estate business    606xx         IL   8.72   \n",
      "3          n           other              personel    917xx         CA  20.00   \n",
      "4          n           other              Personal    972xx         OR  17.94   \n",
      "\n",
      "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
      "0          0.0       1985-01-01             1.0       3.0      0.0    13648.0   \n",
      "1          0.0       1999-04-01             5.0       3.0      0.0     1687.0   \n",
      "2          0.0       2001-11-01             2.0       2.0      0.0     2956.0   \n",
      "3          0.0       1996-02-01             1.0      10.0      0.0     5598.0   \n",
      "4          0.0       1996-01-01             0.0      15.0      0.0    27783.0   \n",
      "\n",
      "  revol_util  total_acc initial_list_status  out_prncp  out_prncp_inv  \\\n",
      "0      83.7%        9.0                   f       0.00           0.00   \n",
      "1       9.4%        4.0                   f       0.00           0.00   \n",
      "2      98.5%       10.0                   f       0.00           0.00   \n",
      "3        21%       37.0                   f       0.00           0.00   \n",
      "4      53.9%       38.0                   f     461.73         461.73   \n",
      "\n",
      "    total_pymnt  total_pymnt_inv  total_rec_prncp  total_rec_int  \\\n",
      "0   5863.155187          5833.84          5000.00         863.16   \n",
      "1   1008.710000          1008.71           456.46         435.17   \n",
      "2   3005.666844          3005.67          2400.00         605.67   \n",
      "3  12231.890000         12231.89         10000.00        2214.92   \n",
      "4   3581.120000          3581.12          2538.27        1042.85   \n",
      "\n",
      "   total_rec_late_fee  recoveries  collection_recovery_fee last_pymnt_d  \\\n",
      "0                0.00        0.00                     0.00     Jan-2015   \n",
      "1                0.00      117.08                     1.11     Apr-2013   \n",
      "2                0.00        0.00                     0.00     Jun-2014   \n",
      "3               16.97        0.00                     0.00     Jan-2015   \n",
      "4                0.00        0.00                     0.00     Jun-2016   \n",
      "\n",
      "   last_pymnt_amnt last_credit_pull_d  collections_12_mths_ex_med  \\\n",
      "0           171.62         2016-06-01                         0.0   \n",
      "1           119.66         2013-09-01                         0.0   \n",
      "2           649.91         2016-06-01                         0.0   \n",
      "3           357.48         2016-04-01                         0.0   \n",
      "4            67.79         2016-06-01                         0.0   \n",
      "\n",
      "   policy_code application_type  acc_now_delinq  chargeoff_within_12_mths  \\\n",
      "0          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "1          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "2          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "3          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "4          1.0       INDIVIDUAL             0.0                       0.0   \n",
      "\n",
      "   delinq_amnt  pub_rec_bankruptcies  tax_liens  \n",
      "0          0.0                   0.0        0.0  \n",
      "1          0.0                   0.0        0.0  \n",
      "2          0.0                   0.0        0.0  \n",
      "3          0.0                   0.0        0.0  \n",
      "4          0.0                   0.0        0.0  \n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv(\"loans_2007.csv\", parse_dates=[\"issue_d\",\"earliest_cr_line\",\"last_credit_pull_d\"], nrows=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage (1000 observations): 1.54\n",
      "Memory usage (3000 observations): 4.62\n",
      "(3000, 52)\n"
     ]
    }
   ],
   "source": [
    "temp = pd.read_csv(\"loans_2007.csv\", nrows=1000)\n",
    "#Figure out a threshold of observations that fits the memory constraint\n",
    "print(\"Memory usage (1000 observations): {}\".format(round(temp.memory_usage(deep=True).sum()/1048576,2)))\n",
    "#1000 rows only is equivalent to 1.55 MB\n",
    "temp = pd.read_csv(\"loans_2007.csv\", nrows=3000)\n",
    "print(\"Memory usage (3000 observations): {}\".format(round(temp.memory_usage(deep=True).sum()/1048576,2)))\n",
    "#3000 rows comes out to about 4.5 MB\n",
    "print(temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 20, 20, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 18]\n",
      "[['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], ['tax_liens'], [], []]\n",
      "65.75837230682373\n"
     ]
    }
   ],
   "source": [
    "#code processes the data in chunks and computes some statistics to identify how to convert some of the column data and clean it\n",
    "\n",
    "chunk_iter = pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "col_dtypes = []\n",
    "col_string_unique_l50 = []\n",
    "no_missing = []\n",
    "memory_footprints = []\n",
    "for chunk in chunk_iter:\n",
    "    col_dtypes.append(chunk.dtypes.value_counts())\n",
    "    #select only the string columns\n",
    "    string_cols = chunk.select_dtypes(include=[\"object\"])\n",
    "    count = 0\n",
    "    for s in string_cols.columns:\n",
    "        share_unique = len(string_cols[s].unique())/len(string_cols[s])\n",
    "        if share_unique < 0.50:\n",
    "            count+=1\n",
    "    #count contains the number of string columns that are less than 50% uniq\n",
    "    col_string_unique_l50.append(count)\n",
    "    #float columns with no missing values and are candidates for conversion\n",
    "    float_cols = chunk.select_dtypes(include=[\"float\"])\n",
    "    for f in float_cols.columns:\n",
    "        no_missing_cols = []\n",
    "        num_missing = len(float_cols[f].index)-float_cols[f].count()\n",
    "        if num_missing == 0:\n",
    "            no_missing_cols.append(f)\n",
    "    no_missing.append(no_missing_cols)\n",
    "    memory_footprints.append(chunk.memory_usage(deep=True).sum()/1048576)   \n",
    "  \n",
    "print(col_string_unique_l50)\n",
    "print(no_missing)\n",
    "total_memory_usage = sum(memory_footprints)\n",
    "print(total_memory_usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         term int_rate grade sub_grade                 emp_title emp_length  \\\n",
      "0   36 months   10.65%     B        B2                       NaN  10+ years   \n",
      "1   60 months   15.27%     C        C4                     Ryder   < 1 year   \n",
      "2   36 months   15.96%     C        C5                       NaN  10+ years   \n",
      "3   36 months   13.49%     C        C1       AIR RESOURCES BOARD  10+ years   \n",
      "4   60 months   12.69%     B        B5  University Medical Group     1 year   \n",
      "\n",
      "  home_ownership verification_status   issue_d  loan_status pymnt_plan  \\\n",
      "0           RENT            Verified  Dec-2011   Fully Paid          n   \n",
      "1           RENT     Source Verified  Dec-2011  Charged Off          n   \n",
      "2           RENT        Not Verified  Dec-2011   Fully Paid          n   \n",
      "3           RENT     Source Verified  Dec-2011   Fully Paid          n   \n",
      "4           RENT     Source Verified  Dec-2011      Current          n   \n",
      "\n",
      "          purpose                 title zip_code addr_state earliest_cr_line  \\\n",
      "0     credit_card              Computer    860xx         AZ         Jan-1985   \n",
      "1             car                  bike    309xx         GA         Apr-1999   \n",
      "2  small_business  real estate business    606xx         IL         Nov-2001   \n",
      "3           other              personel    917xx         CA         Feb-1996   \n",
      "4           other              Personal    972xx         OR         Jan-1996   \n",
      "\n",
      "  revol_util initial_list_status last_pymnt_d last_credit_pull_d  \\\n",
      "0      83.7%                   f     Jan-2015           Jun-2016   \n",
      "1       9.4%                   f     Apr-2013           Sep-2013   \n",
      "2      98.5%                   f     Jun-2014           Jun-2016   \n",
      "3        21%                   f     Jan-2015           Apr-2016   \n",
      "4      53.9%                   f     Jun-2016           Jun-2016   \n",
      "\n",
      "  application_type  \n",
      "0       INDIVIDUAL  \n",
      "1       INDIVIDUAL  \n",
      "2       INDIVIDUAL  \n",
      "3       INDIVIDUAL  \n",
      "4       INDIVIDUAL  \n",
      "40.95293998718262\n"
     ]
    }
   ],
   "source": [
    "#Determine the string columns that can be converted to numeric if \n",
    "#they are cleaned up\n",
    "temp = pd.read_csv(\"loans_2007.csv\", nrows=5)\n",
    "string_cols = temp.select_dtypes(include=[\"object\"])\n",
    "print(string_cols)\n",
    "\n",
    "#Determine columns that have a few unique values and convert them to category type\n",
    "category_cols = [\"grade\",\"sub_grade\",\"emp_length\",\"home_ownership\",\"verification_status\",\"loan_status\",\"addr_state\",\"application_type\"]\n",
    "\n",
    "memory_footprints = []\n",
    "chunk_iter = pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    chunk[\"int_rate\"] = chunk[\"int_rate\"].str.rstrip(\"%\").astype(float)\n",
    "    chunk[\"revol_util\"] = chunk[\"revol_util\"].str.rstrip(\"%\").astype(float)\n",
    "    #chunk[\"term\"] = chunk[\"term\"].str.rstrip(\" months\").astype(int)\n",
    "    for c in category_cols:\n",
    "        chunk[c]=chunk[c].astype(\"category\")\n",
    "    memory_footprints.append(chunk.memory_usage(deep=True).sum()/1048576)   \n",
    "  \n",
    "total_memory_usage = sum(memory_footprints)\n",
    "print(total_memory_usage)\n",
    "#able to cut memory size down from 66MB to 41MB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 38.21\n"
     ]
    }
   ],
   "source": [
    "#optimize numric columns\n",
    "temp = pd.read_csv(\"loans_2007.csv\", nrows=20)\n",
    "float_cols = temp.select_dtypes(include=[\"float\"])\n",
    "#print(float_cols)\n",
    "\n",
    "#float columns that contain missing values\n",
    "#float columns that we can convert to more space efficient sub_type\n",
    "float_int_cols = [\"member_id\",\"loan_amnt\",\"funded_amnt\", \"funded_amnt_inv\",\"annual_inc\",\"delinq_2yrs\",\"inq_last_6mths\",\"open_acc\",\"pub_rec\",\"revol_bal\",\"total_acc\",\"collections_12_mths_ex_med\",\"policy_code\",\"acc_now_delinq\"]\n",
    "\n",
    "#Determine columns that have a few unique values and convert them to category type\n",
    "category_cols = [\"grade\",\"sub_grade\",\"emp_length\",\"home_ownership\",\"verification_status\",\"loan_status\",\"addr_state\",\"application_type\"]\n",
    "\n",
    "memory_footprints = []\n",
    "chunk_iter = pd.read_csv(\"loans_2007.csv\", chunksize=3000)\n",
    "for chunk in chunk_iter:\n",
    "    chunk[\"int_rate\"] = chunk[\"int_rate\"].str.rstrip(\"%\").astype(float)\n",
    "    chunk[\"revol_util\"] = chunk[\"revol_util\"].str.rstrip(\"%\").astype(float)\n",
    "    #chunk[\"term\"] = chunk[\"term\"].str.rstrip(\" months\").astype(int)\n",
    "    for c in category_cols:\n",
    "        chunk[c]=chunk[c].astype(\"category\")\n",
    "    for f in float_int_cols:\n",
    "        chunk[f]=pd.to_numeric(chunk[f],downcast=\"integer\")\n",
    "    memory_footprints.append(chunk.memory_usage(deep=True).sum()/1048576)   \n",
    "  \n",
    "#Space savings here is relatively minor by downcasting floats to integ\n",
    "total_memory_usage = sum(memory_footprints)\n",
    "print(\"Memory usage: {}\".format(round(total_memory_usage,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#function to check if an item is a percentage\n",
    "def is_percentage(item):\n",
    "    if str(item).endswith(\"%\") | str(item).endswith(\" months\"):\n",
    "        try:\n",
    "            float(item[:-1])\n",
    "            return True\n",
    "        except ValueError:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#function to check if an item is a number\n",
    "def is_number(item):\n",
    "    try:\n",
    "        float(item)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "#Function to automate the data compression tasks\n",
    "def compress_chunk(chunk):\n",
    "    #check to make sure that id is valid otherwise exceptions are thrown in the data and storage is not efficient (occurs at tail of data)\n",
    "    id_is_valid = chunk.apply(lambda item: is_number(item[0]), axis=1)\n",
    "    #print(\"Problem w/selection\")\n",
    "    chunk = chunk.loc[id_is_valid == True]\n",
    "    #select string types\n",
    "    string_cols = chunk.select_dtypes(include=[\"object\"])\n",
    "    for s in string_cols.columns:\n",
    "        chunk[s] = chunk[s].str.rstrip()\n",
    "        #check if the column can be mostly considered a percentage or number (thresshold 0.95)\n",
    "        col_is_percentage = chunk.apply(lambda item: is_percentage(item[s]), axis=1)\n",
    "        col_is_number = chunk.apply(lambda item: is_number(item[s]), axis=1)\n",
    "        if col_is_percentage.sum()/len(col_is_percentage) > 0.95:\n",
    "            #print(\"Change to float: \", s)\n",
    "            chunk[s] = chunk[s].str.rstrip(\"%\")\n",
    "            chunk[s] = chunk[s].str.rstrip(\" months\")\n",
    "            try:\n",
    "                chunk[s] = chunk[s].astype(float)\n",
    "            except ValueError:\n",
    "                print(chunk[col_is_percentage==False])\n",
    "                chunk[s] = chunk[s].astype(float,errors=\"ignore\")\n",
    "        elif col_is_number.sum()/len(col_is_number) > 0.95:\n",
    "            #print(s)\n",
    "            #drop rows that do not conform to the number requirements so errors are not thrown\n",
    "            chunk = chunk[col_is_number==True]\n",
    "        else:\n",
    "            chunk[s]=chunk[s].fillna(\"\")\n",
    "            share_unique = len(string_cols[s].unique())/len(string_cols[s])\n",
    "            #Make sure that these columns are not subject issues due to case values (put everything into upper case)\n",
    "            chunk[s] = [st.upper() for st in chunk[s].astype(str)]\n",
    "            if share_unique < 0.50:\n",
    "                #if a small share is unique and the largest value count is the majority then drop this column from data\n",
    "                cnt_large_value = chunk[s].value_counts()[0]\n",
    "                if cnt_large_value/len(chunk[s]) >= 0.99:\n",
    "                    chunk = chunk.drop(s, 1)\n",
    "                else:\n",
    "                    #just change to a category column otherwise\n",
    "                    #print(\"Change to category: \", s)\n",
    "                    chunk[s] = chunk[s].astype(\"category\")\n",
    "                    #print(\"error here\")\n",
    "    #want to check for float cols that are really integers\n",
    "    #that is floor(col) = round(col)\n",
    "    #dataset['deff'] = np.where(dataset['2016-11'] >= dataset['2016-12'], 0,1)\n",
    "    float_cols = chunk.select_dtypes(include=[\"float\"])\n",
    "    float_int_cols = []\n",
    "    for f in float_cols.columns:\n",
    "        #Also check if there is little variation in the float columns and drop these columns\n",
    "        if float_cols[f].std() < 0.0001:\n",
    "            #print(\"Dropping\", f)\n",
    "            chunk = chunk.drop(f, 1)\n",
    "        else:\n",
    "            temp_floor = np.floor(chunk[f]*10)\n",
    "            temp_round = np.round(chunk[f]*10,0)\n",
    "            cnt_diff = np.where(temp_floor==temp_round,0,1).sum()\n",
    "            #if seems like everything is an integer\n",
    "            if cnt_diff == 0:\n",
    "                #print(\"Downcasting\", f)\n",
    "                float_int_cols.append(f)\n",
    "    for f in float_int_cols:\n",
    "        chunk[f]=pd.to_numeric(chunk[f],downcast=\"integer\")\n",
    "    #Drop columns that have too many missing values (greater than 50%)\n",
    "    missing = chunk.isnull().sum()\n",
    "    for key,val in missing.items():\n",
    "        if missing[key]/len(chunk) > 0.50:\n",
    "            chunk = chunk.drop(key, 1)\n",
    "    return chunk\n",
    "\n",
    "# Function to determine optimal chunk size based on memory constraint\n",
    "def optimal_chunk(file, maxmb, encodeval):\n",
    "    mem = 0\n",
    "    numrows = 0\n",
    "    while mem < maxmb:\n",
    "        numrows += 500\n",
    "        temp = pd.read_csv(file, nrows=numrows, encoding=encodeval)\n",
    "        mem = temp.memory_usage(deep=True).sum()/1048576\n",
    "    return numrows-500\n",
    "\n",
    "def compress_data(file,maxmb,dropcols,encodeval,parsedatecols):\n",
    "    memory_footprints_full = []\n",
    "    memory_footprints = []\n",
    "    \n",
    "    #obtain optimal chunk size\n",
    "    opt_chunk = optimal_chunk(file, maxmb, encodeval)\n",
    "    print(\"Optimal chunk for {}MB: {}\".format(maxmb, opt_chunk))\n",
    "    \n",
    "    # Get the memory usage needed prior to compression\n",
    "    chunk_iter = pd.read_csv(file, chunksize=opt_chunk, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    for chunk in chunk_iter:\n",
    "        memory_footprints_full.append(chunk.memory_usage(deep=True).sum()/1048576)\n",
    "    total_memory_usage = sum(memory_footprints_full)\n",
    "    print(\"Memory usage (prior to compression): {}\".format(round(total_memory_usage,2)))\n",
    "    \n",
    "    keep_cols = []\n",
    "    temp = pd.read_csv(file, nrows=1, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    print(\"Number of columns in original file: {}\".format(len(temp.columns)))\n",
    "    for c in temp.columns:\n",
    "        if c not in dropcols:\n",
    "            keep_cols.append(c)\n",
    "            \n",
    "    # Create synthetic data that will help us identify crucial columns to keep so we do not have to read into data frame\n",
    "    temp = pd.read_csv(file, nrows=opt_chunk, usecols=keep_cols, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    temp = compress_chunk(temp)\n",
    "    print(\"Number of columns to keep: {}\".format(len(temp.columns)))\n",
    "    print(temp.columns)\n",
    "    newdata = []\n",
    "    # use the optimal chunk size and columns to keep to read in the chunks\n",
    "    chunk_iter = pd.read_csv(file, usecols=temp.columns, chunksize=opt_chunk, encoding=encodeval, parse_dates=parsedatecols)\n",
    "    for chunk in chunk_iter:\n",
    "        chunk = compress_chunk(chunk)       \n",
    "        memory_footprints.append(chunk.memory_usage(deep=True).sum()/1048576)\n",
    "        #merge data into new set\n",
    "        newdata.append(chunk)\n",
    "        #try:\n",
    "        #    newdata=pd.concat([newdata, chunk], axis=0)\n",
    "        #except NameError:\n",
    "        #    newdata=chunk\n",
    "    total_memory_usage = sum(memory_footprints)\n",
    "    print(\"Memory usage (after compression): {}\".format(round(total_memory_usage,2)))\n",
    "    #print(\"Memory usage (newdata): {}\".format(round(newdata.memory_usage(deep=True).sum()/1048576,2)))\n",
    "    return newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal chunk for 5MB: 3000\n",
      "Memory usage (prior to compression): 56.51\n",
      "Number of columns in original file: 52\n",
      "Number of columns to keep: 43\n",
      "Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n",
      "       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
      "       'emp_length', 'home_ownership', 'annual_inc', 'verification_status',\n",
      "       'issue_d', 'loan_status', 'purpose', 'title', 'zip_code', 'addr_state',\n",
      "       'dti', 'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'out_prncp',\n",
      "       'out_prncp_inv', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
      "       'total_rec_int', 'total_rec_late_fee', 'recoveries',\n",
      "       'collection_recovery_fee', 'last_pymnt_d', 'last_pymnt_amnt',\n",
      "       'last_credit_pull_d', 'pub_rec_bankruptcies'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage (after compression): 14.7\n"
     ]
    }
   ],
   "source": [
    "#we want data that is less than 5 MB per chunk (each compressed data chunk is stored in the list compressed data)\n",
    "compressed_data = compress_data(\"loans_2007.csv\", 5, dropcols=[], encodeval=\"ISO-8859-1\", \n",
    "                                parsedatecols=[\"issue_d\",\"earliest_cr_line\",\"last_pymnt_d\",\"last_credit_pull_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  member_id  loan_amnt  funded_amnt  funded_amnt_inv        term  \\\n",
      "0  1077501    1296599       5000         5000           4975.0   36 MONTHS   \n",
      "1  1077430    1314167       2500         2500           2500.0   60 MONTHS   \n",
      "2  1077175    1313524       2400         2400           2400.0   36 MONTHS   \n",
      "3  1076863    1277178      10000        10000          10000.0   36 MONTHS   \n",
      "4  1075358    1311748       3000         3000           3000.0   60 MONTHS   \n",
      "\n",
      "   int_rate  installment grade sub_grade                 emp_title emp_length  \\\n",
      "0     10.65       162.87     B        B2                            10+ YEARS   \n",
      "1     15.27        59.83     C        C4                     RYDER   < 1 YEAR   \n",
      "2     15.96        84.33     C        C5                            10+ YEARS   \n",
      "3     13.49       339.31     C        C1       AIR RESOURCES BOARD  10+ YEARS   \n",
      "4     12.69        67.79     B        B5  UNIVERSITY MEDICAL GROUP     1 YEAR   \n",
      "\n",
      "  home_ownership  annual_inc verification_status    issue_d  loan_status  \\\n",
      "0           RENT     24000.0            VERIFIED 2011-12-01   FULLY PAID   \n",
      "1           RENT     30000.0     SOURCE VERIFIED 2011-12-01  CHARGED OFF   \n",
      "2           RENT     12252.0        NOT VERIFIED 2011-12-01   FULLY PAID   \n",
      "3           RENT     49200.0     SOURCE VERIFIED 2011-12-01   FULLY PAID   \n",
      "4           RENT     80000.0     SOURCE VERIFIED 2011-12-01      CURRENT   \n",
      "\n",
      "          purpose                 title zip_code addr_state    dti  \\\n",
      "0     CREDIT_CARD              COMPUTER    860XX         AZ  27.65   \n",
      "1             CAR                  BIKE    309XX         GA   1.00   \n",
      "2  SMALL_BUSINESS  REAL ESTATE BUSINESS    606XX         IL   8.72   \n",
      "3           OTHER              PERSONEL    917XX         CA  20.00   \n",
      "4           OTHER              PERSONAL    972XX         OR  17.94   \n",
      "\n",
      "   delinq_2yrs earliest_cr_line  inq_last_6mths  open_acc  pub_rec  revol_bal  \\\n",
      "0            0       1985-01-01               1         3        0      13648   \n",
      "1            0       1999-04-01               5         3        0       1687   \n",
      "2            0       2001-11-01               2         2        0       2956   \n",
      "3            0       1996-02-01               1        10        0       5598   \n",
      "4            0       1996-01-01               0        15        0      27783   \n",
      "\n",
      "   revol_util  total_acc  out_prncp  out_prncp_inv   total_pymnt  \\\n",
      "0        83.7          9       0.00           0.00   5863.155187   \n",
      "1         9.4          4       0.00           0.00   1008.710000   \n",
      "2        98.5         10       0.00           0.00   3005.666844   \n",
      "3        21.0         37       0.00           0.00  12231.890000   \n",
      "4        53.9         38     461.73         461.73   3581.120000   \n",
      "\n",
      "   total_pymnt_inv  total_rec_prncp  total_rec_int  total_rec_late_fee  \\\n",
      "0          5833.84          5000.00         863.16                0.00   \n",
      "1          1008.71           456.46         435.17                0.00   \n",
      "2          3005.67          2400.00         605.67                0.00   \n",
      "3         12231.89         10000.00        2214.92               16.97   \n",
      "4          3581.12          2538.27        1042.85                0.00   \n",
      "\n",
      "   recoveries  collection_recovery_fee last_pymnt_d  last_pymnt_amnt  \\\n",
      "0        0.00                     0.00   2015-01-01           171.62   \n",
      "1      117.08                     1.11   2013-04-01           119.66   \n",
      "2        0.00                     0.00   2014-06-01           649.91   \n",
      "3        0.00                     0.00   2015-01-01           357.48   \n",
      "4        0.00                     0.00   2016-06-01            67.79   \n",
      "\n",
      "  last_credit_pull_d  pub_rec_bankruptcies  \n",
      "0         2016-06-01                     0  \n",
      "1         2013-09-01                     0  \n",
      "2         2016-06-01                     0  \n",
      "3         2016-04-01                     0  \n",
      "4         2016-06-01                     0  \n",
      "id                                  int64\n",
      "member_id                           int32\n",
      "loan_amnt                           int32\n",
      "funded_amnt                         int32\n",
      "funded_amnt_inv                   float64\n",
      "term                             category\n",
      "int_rate                          float64\n",
      "installment                       float64\n",
      "grade                            category\n",
      "sub_grade                        category\n",
      "emp_title                          object\n",
      "emp_length                       category\n",
      "home_ownership                   category\n",
      "annual_inc                        float64\n",
      "verification_status              category\n",
      "issue_d                    datetime64[ns]\n",
      "loan_status                      category\n",
      "purpose                          category\n",
      "title                            category\n",
      "zip_code                         category\n",
      "addr_state                       category\n",
      "dti                               float64\n",
      "delinq_2yrs                          int8\n",
      "earliest_cr_line           datetime64[ns]\n",
      "inq_last_6mths                       int8\n",
      "open_acc                             int8\n",
      "pub_rec                              int8\n",
      "revol_bal                           int32\n",
      "revol_util                        float64\n",
      "total_acc                            int8\n",
      "out_prncp                         float64\n",
      "out_prncp_inv                     float64\n",
      "total_pymnt                       float64\n",
      "total_pymnt_inv                   float64\n",
      "total_rec_prncp                   float64\n",
      "total_rec_int                     float64\n",
      "total_rec_late_fee                float64\n",
      "recoveries                        float64\n",
      "collection_recovery_fee           float64\n",
      "last_pymnt_d               datetime64[ns]\n",
      "last_pymnt_amnt                   float64\n",
      "last_credit_pull_d         datetime64[ns]\n",
      "pub_rec_bankruptcies                 int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(compressed_data[0].head(5))\n",
    "print(compressed_data[0].dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Data compression can significantly increase the efficiency and usability of data.  Significant gains were observed in converting from string to integers, string to category, and float to integers.  The functions that were created above makes it easy to determine the optimal chunk size to read in given a certain level of memory constraints and apply a similar process to other file types in order to compress the data.  We found significant savings in memory going from 66MB to 14MB.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
